{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3df966",
   "metadata": {},
   "source": [
    "#### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a615e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM #, GenerationConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb48bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "MAX_TOKEN_COUNT = 5000\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "BOXED_PATTERN = r'\\\\boxed\\{(.*?)\\}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6c567",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e47a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "linal = {\n",
    "    r\"Decompose this vector $x\\in X$ according to the basis $\\{e_{i}\\}_{i=1}{n}$ of \\\n",
    "the linear space $X$. \\\\ \\\n",
    " \\\n",
    "\\begin{equation*} \\\n",
    "x = \\begin{pmatrix} 6 & 2 & 9 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "  e_{1} = \\begin{pmatrix} 5 & 0 & 4 \\end{pmatrix}^{\\math{T}}, \\quad \\\n",
    "  e_{2} = \\begin{pmatrix} 5 & -1 & 0 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "  e_{3} = \\begin{pmatrix} -1 & 0 & 4 \\end{pmatrix}^{\\mathrm{T}}. \\\n",
    "\\end{equation*}\" : r\"[73/24, -2, -19/24]\",\n",
    "\n",
    "r\"Find some basis for the space $X$ defined as a linear shell \\\n",
    "of vectors $\\{x_{i}\\}_{i=1}^{m}$. \\\n",
    " \\\n",
    "\\begin{gather*} \\\n",
    "  x_{1} = \\begin{pmatrix} -1 & 4 & -3 & -2 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "  x_{2} = \\begin{pmatrix} 3 & -7 & 5 & 3 \\end{pmatrix}^{\\mathrm{T}}, \\\\ \\\n",
    "  x_{3} = \\begin{pmatrix} 3 & -2 & 1 & 0 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "  x_{4} = \\begin{pmatrix} -4 & 1 & 0 & 1 \\end{pmatrix}^{\\mathrm{T}}. \\\n",
    "\\end{gather*}\" : r\"\\begin{gather*} \\\n",
    "        \\begin{pmatrix} -1 & 4 & -3 & -2 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "        \\begin{pmatrix} 0 & 5 & -4 & -3 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "        \\begin{pmatrix}  0 & 0 & -4 & 9 \\end{pmatrix}^{\\mathrm{T}}. \\\n",
    "    \\end{gather*}\",\n",
    "\n",
    "\n",
    "r\"Find the basis of the intersection of subspaces $L_{1}$ and $L_{2}$ of a linear \\\n",
    "space $X$ spanned by the corresponding vector systems $\\{x_{i}\\}_{i=1}^{p}$ and \\\n",
    "$\\{y_{j}\\}_{j=1}^{q}$ respectively. \\\n",
    " \\\n",
    "\\begin{gather*} \\\n",
    "  L_{1} = \\left\\langle (1,2,3,1,1)^\\mathrm{T}, (1,0,1,-2,-2)^\\mathrm{T}, \\\n",
    "    (2,0,1,-1,0)^\\mathrm{T},(0,1,1,0,0)^\\mathrm{T} \\right\\rangle, \\\\ \\\n",
    "  L_{2} = \\left\\langle (1,2,0,0,2)^\\mathrm{T}, (0,1,-2,3,-3)^\\mathrm{T}, \\\n",
    "    (-1,2,1,2,0)^\\mathrm{T}, (1,1,-2,0,0)^\\mathrm{T} \\right\\rangle. \\\n",
    "\\end{gather*}\" : r\"$(0,0,1,0,0)^\\mathrm{T}$, $(0,72,0,43,0)^\\mathrm{T}$, $(18,-0,0,55,-76)^\\mathrm{T}$.\",\n",
    "\n",
    "r\"Find the coefficients of the linear form $f\\in X^{\\ast}$ in a given basis \\\n",
    "$\\{e_{i}\\}_{i=1}{n}$ spaces $X$. \\\n",
    " \\\n",
    "\\begin{gather*} \\\n",
    "f(x) = 4 \\xi^{1} + 2 \\xi^{2} + \\xi^{3}, \\\\ \\\n",
    "e_{1} =\\begin{pmatrix} 5 & 0 & 4 \\end{pmatrix}^{\\math{T}}, \\quad \\\n",
    "  e_{2} = \\begin{pmatrix} 5 & -1 & 0 \\end{pmatrix}^{\\mathrm{T}}, \\quad \\\n",
    "  e_{3} = \\begin{pmatrix} -1 & 0 & 4 \\end{pmatrix}^{\\mathrm{T}}. \\\n",
    "\\end{gather*}\" : r\"(24, 18, 0)\",\n",
    "\n",
    "r\"Find the basis of a linear shell $L$ given by a system of linear \\\n",
    "algebraic equations. \\\n",
    " \\\n",
    "\\begin{gather*} \\\n",
    "  \\left\\{ \\begin{array}{lcr} \\\n",
    "    x_1 - x_2 + x_3 - x_4 &=& 0; \\\\ \\\n",
    "    x_1 + x_2 + 2x_3 + 3x_4 &=& 0;\\\\ \\\n",
    "    2x_1 + 4x_2 + 5x_3 + 10x_4 &=& 0;\\\\ \\\n",
    "    2x_1 - 4x_2 + x_3 - 6x_4 &=& 0; \\\n",
    "  \\end{array} \\right. \\\n",
    "\\end{gather*}\": r\"$(3, 1, -2, 0)^\\mathrm{T}$, $(5, 0, -4, 1)^\\mathrm{T}$\", \n",
    "\n",
    "r\"Find the coordinates of the vector $x$ of the linear space $X$ in the basis \\\n",
    "$\\{\\$\\{\\tilde e_{j}\\}_{j=1}^{n}$ if its coordinates in the basis are known \\\n",
    "$\\{e_{i}\\}_{i=1}^{n}$. \\\n",
    " \\\n",
    "\\begin{gather*} \\\n",
    "  x = \\begin{pmatrix} 6 & 2 & 9 \\end{pmatrix}^{\\mathrm{T}}, \\\\ \\\n",
    "  \\tilde e_{1} = 5e_{1} + 4e_{3}, \\quad \\\n",
    "  \\tilde e_{2} = 5e_{1} - e_{2} , \\quad \\\n",
    "  \\tilde e_{3} = -e_{1} + 4e_{3}. \\\n",
    "\\end{gather*}\" : r\"$(\\frac{73}{24}, -2, -\\frac{19}{24})^\\mathrm{T}$\"\n",
    "}\n",
    "linal_df = []\n",
    "for k, v in linal.items():\n",
    "    task = {}\n",
    "    task[\"subfield\"] = \"GeolinLinal\"\n",
    "    task[\"question\"] = r\"Please write valid Lean code to solve the problem using the Lean engine: \\n\" + k\n",
    "    task[\"final_answer\"] =  \"['$\" + v + \"$']\"\n",
    "    task[\"solution\"] = None\n",
    "    task[\"solution_length\"] = None\n",
    "    linal_df.append(task)\n",
    "\n",
    "linal_df = pd.DataFrame(linal_df)\n",
    "linal_df.index = np.arange(0, len(linal_df))\n",
    "\n",
    "linal_df.to_csv(\"/home/anmilka/different/linal_df.csv\")\n",
    "\n",
    "linal_dict = linal_df.T.to_dict().values()\n",
    "print(len(linal_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2121b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subfield</th>\n",
       "      <th>question</th>\n",
       "      <th>final_answer</th>\n",
       "      <th>solution</th>\n",
       "      <th>solution_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GeolinLinal</td>\n",
       "      <td>Please write valid Lean code to solve the prob...</td>\n",
       "      <td>['$[73/24, -2, -19/24]$']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GeolinLinal</td>\n",
       "      <td>Please write valid Lean code to solve the prob...</td>\n",
       "      <td>['$\\begin{gather*} \\\\n        \\begin{pmatrix} ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GeolinLinal</td>\n",
       "      <td>Please write valid Lean code to solve the prob...</td>\n",
       "      <td>['$$(0,0,1,0,0)^\\mathrm{T}$, $(0,72,0,43,0)^\\m...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GeolinLinal</td>\n",
       "      <td>Please write valid Lean code to solve the prob...</td>\n",
       "      <td>['$(24, 18, 0)$']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GeolinLinal</td>\n",
       "      <td>Please write valid Lean code to solve the prob...</td>\n",
       "      <td>['$$(3, 1, -2, 0)^\\mathrm{T}$, $(5, 0, -4, 1)^...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subfield                                           question  \\\n",
       "0  GeolinLinal  Please write valid Lean code to solve the prob...   \n",
       "1  GeolinLinal  Please write valid Lean code to solve the prob...   \n",
       "2  GeolinLinal  Please write valid Lean code to solve the prob...   \n",
       "3  GeolinLinal  Please write valid Lean code to solve the prob...   \n",
       "4  GeolinLinal  Please write valid Lean code to solve the prob...   \n",
       "\n",
       "                                        final_answer solution solution_length  \n",
       "0                          ['$[73/24, -2, -19/24]$']     None            None  \n",
       "1  ['$\\begin{gather*} \\\\n        \\begin{pmatrix} ...     None            None  \n",
       "2  ['$$(0,0,1,0,0)^\\mathrm{T}$, $(0,72,0,43,0)^\\m...     None            None  \n",
       "3                                  ['$(24, 18, 0)$']     None            None  \n",
       "4  ['$$(3, 1, -2, 0)^\\mathrm{T}$, $(5, 0, -4, 1)^...     None            None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec74acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boxed_content(text):\n",
    "    start_index = text.rfind(r'\\boxed{')\n",
    "    if start_index == -1:\n",
    "        return None\n",
    "    start_index += len(r'\\boxed{')    \n",
    "    stack = ['{']\n",
    "    content = []\n",
    "\n",
    "    for i in range(start_index, len(text)):\n",
    "        char = text[i]\n",
    "        content.append(char)\n",
    "        if char == '{':\n",
    "            stack.append(char)\n",
    "        elif char == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "            if not stack:\n",
    "                return ''.join(content[:-1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef40a4d",
   "metadata": {},
   "source": [
    "### deepseek-math-7b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823ee1d4-6a5c-4c6c-ad6a-375a8cce88af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 14:54:02.894551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-04 14:54:02.894626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-04 14:54:02.896870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-04 14:54:02.908171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-04 14:54:04.539896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8461b6a8309d40619895fafe8569ee34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "1it [01:20, 80.58s/it]This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "6it [08:45, 87.66s/it] \n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/deepseek-math-7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_Fast=False)\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "\n",
    "for _, task in tqdm(enumerate(linal_dict)):\n",
    "    question = task['question'] +  ' Please reason step by step, and put your final answer within \\\\boxed{}.'\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_tensor.to(model.device), max_new_tokens=MAX_TOKEN_COUNT)\n",
    "\n",
    "    detailed_result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    result = find_boxed_content(detailed_result)\n",
    "\n",
    "    task['deepseek-math_detailed_result'] = detailed_result\n",
    "    task['deepseek-math_result'] = result\n",
    "\n",
    "pd.DataFrame(linal_dict).to_csv(\"/home/anmilka/different/lean_output/linal_deepseek.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf13556",
   "metadata": {},
   "source": [
    "### Qwen2.5-Math-7B CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1299ef0-8fea-4ffa-b27d-eb2694b33289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b360c867c94646cea3ad60cc19d51ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9069b6f24044bd8c046b712f9f65bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  42%|####1     | 1.66G/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31e12a0a6604cc288e8212d10f50f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaf3204fb3b4723b8cfd507cef27867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa0ab3f58ae41fbb03e90822b458747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f798c737c12648b2849af9b3e8c32f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd3328c686048a6bb0e8ff1aba6983c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/161 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bfa1b3b929402b98563888787fe0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fbd10b52f446a49ea7535f5b903b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf199f045cc4812ac391f38e35fc0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865f2ca5da0940ca8adad61e05fcee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [08:06, 81.08s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-Math-7B-Instruct\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "for _, task in tqdm(enumerate(linal_dict)):\n",
    "    question = task['question']\n",
    "\n",
    "    # CoT\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=MAX_TOKEN_COUNT)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    detailed_result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    result = find_boxed_content(detailed_result)\n",
    "\n",
    "    task['Qwen2.5-cot_detailed_result'] = detailed_result\n",
    "    task['Qwen2.5-cot_result'] = result\n",
    "\n",
    "pd.DataFrame(linal_dict).to_csv(\"/home/anmilka/different/lean_output/linal_qwen_cot.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66710c",
   "metadata": {},
   "source": [
    "### Qwen2-Math-7B TIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ed8cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [06:57, 69.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for _, task in tqdm(enumerate(linal_dict)):\n",
    "    question = task['question']\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Please integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    " \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=MAX_TOKEN_COUNT)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    detailed_result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    result = find_boxed_content(detailed_result)\n",
    "\n",
    "    task['Qwen2.5-tir_detailed_result'] = detailed_result\n",
    "    task['Qwen2.5-tir_result'] = result\n",
    "\n",
    "pd.DataFrame(linal_dict).to_csv(\"/home/anmilka/different/lean_output/linal_qwen_tir.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd180c",
   "metadata": {},
   "source": [
    "### DeepSeek-r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62399c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1719a62cf0be4708a933ef14c872a876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47226691a5af4b568735f5fb9c8389a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9884d438a09d45cda20398d98430264e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c00965a1644c6b8d0c5b215132d605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8310f0436f6245039bd789a680c507ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707cf0cabf8b4885af7303d4dd1a98ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca8f48b6fdb4d5f94dda36c39134e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78c451e541644fa996f0d7b814150ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57a89656d2d4b2b84c3ab491eff469f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "1it [01:43, 103.52s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "2it [07:15, 237.85s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "3it [12:50, 282.04s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "4it [18:20, 301.28s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "5it [20:51, 246.81s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "6it [22:36, 226.04s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "for _, task in tqdm(enumerate(linal_dict)):\n",
    "    question = task['question']\n",
    "\n",
    "    # CoT\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=MAX_TOKEN_COUNT)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    detailed_result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    result = find_boxed_content(detailed_result)\n",
    "\n",
    "    task['DeepSeek-r1-Qwen_detailed_result'] = detailed_result\n",
    "    task['DeepSeek-r1-Qwen_result'] = result\n",
    "\n",
    "pd.DataFrame(linal_dict).to_csv(\"/home/anmilka/different/lean_output/linal_DeepSeek-r1-Qwen.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
